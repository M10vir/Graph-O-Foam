{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f216e1a8",
   "metadata": {},
   "source": [
    "\n",
    "# Images â†’ Foam half-life (baseline)\n",
    "Quick baseline that pairs the converted foam stacks with tabular features to predict the foam half-life (as defined in the converter: first time the height or BC hits half the max).\n",
    "- Loads NSID `.h5` files from `../data/foam`\n",
    "- Builds a compact feature table (bubble metrics + image summary stats)\n",
    "- Trains a scikit-learn random forest regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data/foam\").resolve()\n",
    "h5_files = sorted(DATA_DIR.glob(\"*.h5\"))\n",
    "if not h5_files:\n",
    "    raise FileNotFoundError(\"No .h5 files in ../data/foam. Run scripts/convert_foam_to_h5.py first.\")\n",
    "\n",
    "# Pick one dataset to start; switch index if desired\n",
    "H5_PATH = h5_files[0]\n",
    "print(\"Using\", H5_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0796433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from SciFiReaders import NSIDReader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load NSID content\n",
    "reader = NSIDReader(H5_PATH)\n",
    "datasets = reader.read()\n",
    "im_ds = datasets[\"Channel_000\"]\n",
    "feat_ds = datasets[\"Channel_001\"]\n",
    "\n",
    "feature_names = [\n",
    "    f.decode() if isinstance(f, (bytes, bytearray)) else f\n",
    "    for f in feat_ds.metadata.get(\"feature_names\", [])\n",
    "]\n",
    "X = pd.DataFrame(feat_ds.compute(), columns=feature_names)\n",
    "\n",
    "images = im_ds.compute().astype(np.float32) / 255.0\n",
    "# Lightweight image summary stats\n",
    "flat = images.reshape(images.shape[0], -1)\n",
    "X[\"intensity_mean\"] = flat.mean(axis=1)\n",
    "X[\"intensity_std\"] = flat.std(axis=1)\n",
    "\n",
    "label_val = float(im_ds.original_metadata.get(\"half_life_s\", np.nan))\n",
    "y = np.full(len(X), label_val, dtype=np.float32)\n",
    "\n",
    "print(f\"Frames: {len(X)}, Pixel size (mm): {im_ds.original_metadata.get('pixel_size_mm')}\")\n",
    "print(\"Half-life target (every frame uses the dataset value):\", label_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572865c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train/test split + model\n",
    "train_cols = [c for c in X.columns if c != \"half_life_s\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X[train_cols], y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"rf\", RandomForestRegressor(n_estimators=150, random_state=42)),\n",
    "    ]\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "print(f\"MAE (s): {mae:.3f}\")\n",
    "print(\"Dataset-wide predicted half-life (mean over frames):\", model.predict(X[train_cols]).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fcf426",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rf = model.named_steps[\"rf\"]\n",
    "importances = rf.feature_importances_\n",
    "order = np.argsort(importances)[::-1][:10]\n",
    "\n",
    "plt.barh(range(len(order)), importances[order][::-1])\n",
    "plt.yticks(range(len(order)), [train_cols[i] for i in order][::-1])\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.title(\"Top predictors of half-life\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
